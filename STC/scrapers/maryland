import requests
from bs4 import BeautifulSoup
import re
import urllib.request

import csv
import pandas as pd

URL = "https://academiccatalog.umd.edu/undergraduate/approved-courses/"
page = requests.get(URL)

soup = BeautifulSoup(page.text, 'html.parser')
results = soup.findAll('a')

departments = [] #array of all department links
for link in results:
    #note: this actually filters and gets relevant links
    #but it may not be the best for generalizing-->
    #is there a standard structure for department links?
    p =  re.search(r'\/approved-courses\/([^"]+)', str(link))
    #could possible do something with the first group?
    if p:
        departments.append("http://academiccatalog.umd.edu/undergraduate" + p.group(0))

departments_of_interest = [departments[2], departments[5], departments[10], departments[21]]

filename = "maryland" + ".csv"

csv_writer = csv.writer(open(filename, 'w'))
csv_writer.writerow(["Title", "Credit",  "Desc"])
keywords = ["agri", "agricultural", "food", "animal"] # variations or no?


for dep in departments_of_interest:
    
    URL = dep
    page = requests.get(URL)
    soup = BeautifulSoup(page.text, 'html.parser')
    
    #how will classes differ across sites?
    courses = soup.findAll(class_="courseblock")
    for course in courses:
        
        full = course.find(class_= "courseblocktitle").text
        
        if "(" in full:
            lst = full.split("(")
            title = lst[0]
            credit = lst[1]
        
        desc = course.find(class_= "courseblockdesc").text
       
        

            
        for key in keywords: #<-- filtered
            if (key in title or key in desc):
                csv_writer.writerow([title, credit, desc])

  
