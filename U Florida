import requests
from bs4 import BeautifulSoup
import re
import urllib.request
import csv
import pandas as pd

URL = "https://catalog.ufl.edu/UGRD/courses/"
page = requests.get(URL)

soup = BeautifulSoup(page.text, 'html.parser')
results = soup.findAll('a')

departments = [] #array of all department links
for link in results:
    #note: this actually filters and gets relevant links
    #but it may not be the best for generalizing-->
    #is there a standard structure for department links?
    

    p =  re.search(r'\/UGRD\/courses\/([^"]+)', str(link))
    #could possible do something with the first group?
    if p:
        departments.append("https://catalog.ufl.edu/" + p.group(0))

departments_of_interest = [departments[5], departments[6], departments[7], departments[8]]

filename = "Florida" + ".csv"

csv_writer = csv.writer(open(filename, 'w'))
csv_writer.writerow(["Title", "Credit",  "Desc"])
keywords = ["agri", "agricultural", "food", "animal"] # variations or no?

for dep in departments_of_interest:
    URL = dep
    page = requests.get(URL)
    soup = BeautifulSoup(page.text, 'html.parser')
    #how will classes differ across sites?
    courses = soup.findAll(class_="courseblock courseblocktoggle")
    for course in courses:
        intro = course.find(class_="courseblocktitle")
        credit = intro.find(class_='credits').text
        title = intro.text
        desc = course.find(class_="courseblockdesc").text

        
        
        for key in keywords: #filtered
            if (re.search(key, title, flags=re.IGNORECASE) or 
                re.search(key, desc, flags=re.IGNORECASE)):
                csv_writer.writerow([title, credit, desc])
